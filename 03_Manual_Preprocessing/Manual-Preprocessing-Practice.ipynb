{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1317381",
   "metadata": {},
   "source": [
    "##### `Manual Preprocessing`\n",
    "Problem Statement: Estimate Weight(Col) of Car based on other Factors (Cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba0f16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Data Size: (94, 28)\n",
      "Duplicates Count Before Removal: 1\n",
      "Duplicates Count After Removal: 0\n",
      "Missing Column Values Before Replacing:  3\n",
      "Missing Column Values After Replacing: 0\n",
      "After Sanity Changes Data Size: (93, 28)\n",
      "Linear Regression Model Train Score 1.0\n",
      "Linear Regression Model Test Score 0.8414224279367748\n",
      "Train Results: RMSE:0.00 |MAE: 0.00 |MAPE: 0.00% |R2_SCORE: 100.00%\n",
      "Test Results: RMSE:238.29 |MAE: 179.38 |MAPE: 5.99% |R2_SCORE: 84.14%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max.Price</th>\n",
       "      <th>MPG.city</th>\n",
       "      <th>MPG.highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>...</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn.circle</th>\n",
       "      <th>Rear.seat.room</th>\n",
       "      <th>Luggage.room</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Make</th>\n",
       "      <th>Weight_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>30.8</td>\n",
       "      <td>37.7</td>\n",
       "      <td>44.6</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>106</td>\n",
       "      <td>65</td>\n",
       "      <td>37</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 100</td>\n",
       "      <td>3313.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pontiac</td>\n",
       "      <td>Sunbird</td>\n",
       "      <td>Compact</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>Front</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>181</td>\n",
       "      <td>101</td>\n",
       "      <td>66</td>\n",
       "      <td>39</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>Pontiac Sunbird</td>\n",
       "      <td>2575.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer    Model     Type  Min.Price  Price  Max.Price  MPG.city  \\\n",
       "0         Audi      100  Midsize       30.8   37.7       44.6        19   \n",
       "1      Pontiac  Sunbird  Compact        9.4   11.1       12.8        23   \n",
       "\n",
       "   MPG.highway AirBags DriveTrain  ... Passengers  Length  Wheelbase  Width  \\\n",
       "0           26    None      Front  ...          6     190        106     65   \n",
       "1           31    None      Front  ...          5     181        101     66   \n",
       "\n",
       "   Turn.circle Rear.seat.room  Luggage.room   Origin             Make  \\\n",
       "0           37           31.0          17.0  non-USA         Audi 100   \n",
       "1           39           25.0          13.0      USA  Pontiac Sunbird   \n",
       "\n",
       "   Weight_pred  \n",
       "0      3313.16  \n",
       "1      2575.00  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter Warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "#-----------------------\n",
    "# Step-1: Data Ingestion\n",
    "#-----------------------\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Cars93.csv\", keep_default_na=False, na_values=[\"\", \"NA\"])\n",
    "print(f'Actual Data Size: {df.shape}')\n",
    "\n",
    "#-----------------------------------\n",
    "# Step-2: Perform Data Sanity Checks\n",
    "#-----------------------------------\n",
    "\n",
    "#Check duplicates\n",
    "print('Duplicates Count Before Removal:', df.duplicated().sum())\n",
    "# Drop Duplicates\n",
    "df = df.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "#Check duplicates\n",
    "print('Duplicates Count After Removal:', df.duplicated().sum())\n",
    "\n",
    "# Check Missing Values in File\n",
    "\n",
    "m_before = df.isna().sum()\n",
    "print(\"Missing Column Values Before Replacing: \", m_before[m_before > 0].size)\n",
    "\n",
    "# If Exist Replace as below\n",
    "    # Categorical Values with most occured value\n",
    "    # Numeric value with mean or median\n",
    "\n",
    "# Create a replacer method to do the above replacing values\n",
    "def replacer(df):\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    num_cols = df.select_dtypes(include='number').columns\n",
    "    for col in df.columns:\n",
    "        if col in cat_cols:\n",
    "            mode = df[col].mode()[0]\n",
    "            df[col] = df[col].fillna(mode)\n",
    "        elif col in num_cols:\n",
    "            mean = df[col].mean()\n",
    "            df[col] = df[col].fillna(mean)\n",
    "\n",
    "replacer(df)\n",
    "\n",
    "m_after = df.isna().sum()\n",
    "print(\"Missing Column Values After Replacing:\", m_after[m_after > 0].size)\n",
    "# Check Data Size\n",
    "print('After Sanity Changes Data Size:', df.shape)\n",
    "\n",
    "# Note: Categoric values which has huge unique values needs to be discarded/dropped from dataframe as \n",
    "# One Hot Encoding will create large amoun of columns which is not ideal for prediction\n",
    "cat_uniq_cols = df.select_dtypes(include=\"object\").nunique()\n",
    "high_cat_uniq_cols = cat_uniq_cols[cat_uniq_cols/len(df) >= 0.9].index\n",
    "df = df.drop(columns = high_cat_uniq_cols )\n",
    "\n",
    "#------------------------\n",
    "# Step-3 Separate X and Y\n",
    "#------------------------\n",
    "\n",
    "X = df.drop(columns=['id', 'Weight'])\n",
    "Y = df[\"Weight\"]\n",
    "\n",
    "#--------------------------------\n",
    "#Step-4: Apply Preprocessing on X\n",
    "#--------------------------------\n",
    "\n",
    "# Apply OHE(OneHotEncoding) on categorical columns\n",
    "X_Cat = X.select_dtypes(include='object')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(\n",
    "    handle_unknown='ignore', sparse_output=False, drop='first'\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "ohe.fit(X_Cat)\n",
    "X_Cat_Pre = ohe.transform(X_Cat)\n",
    "\n",
    "# Apply scaling on numeric columns\n",
    "X_Num = X.select_dtypes(include='number')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().set_output(transform='pandas')\n",
    "scaler.fit(X_Num)\n",
    "X_Num_Pre = scaler.transform(X_Num)\n",
    "\n",
    "# Join All columns as X_Pre\n",
    "X_Pre = X_Num_Pre.join(X_Cat_Pre)\n",
    "X_Pre.head(1)\n",
    "\n",
    "#------------------------\n",
    "#Step-5: Train Test Split\n",
    "#------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain , ytest = train_test_split(X_Pre, Y, train_size=0.25, random_state=21)\n",
    "\n",
    "#-------------------\n",
    "#Step-6: Build Model\n",
    "#-------------------\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(xtrain, ytrain)\n",
    "print('Linear Regression Model Train Score', model.score(xtrain , ytrain))\n",
    "print('Linear Regression Model Test Score', model.score(xtest , ytest))\n",
    "\n",
    "#----------------------\n",
    "#Step-6: Evaluate Model\n",
    "#----------------------\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    ")\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    ypred = model.predict(x)\n",
    "    rmse = root_mean_squared_error(y, ypred); mae = mean_absolute_error(y, ypred)\n",
    "    mape = mean_absolute_percentage_error(y, ypred); r2 = r2_score(y, ypred)\n",
    "    return f\"RMSE:{rmse:.2f} |MAE: {mae:.2f} |MAPE: {mape:.2%} |R2_SCORE: {r2:.2%}\"\n",
    "\n",
    "print(\"Train Results:\", evaluate_model(model, xtrain, ytrain))\n",
    "print(\"Test Results:\", evaluate_model(model, xtest, ytest))\n",
    "\n",
    "#------------------------\n",
    "# Step-7: Model Inference\n",
    "#------------------------\n",
    "\n",
    "xnew = pd.read_csv(\"sample.csv\", na_values = [\"\", \"NA\"], keep_default_na = False)\n",
    "# Data Sanity check for new file\n",
    "replacer(xnew)\n",
    "\n",
    "xnew_cat = xnew.select_dtypes(include = \"object\").drop(columns = high_cat_uniq_cols)\n",
    "xnew_cat_pre = ohe.transform(xnew_cat)\n",
    "\n",
    "xnew_num = xnew.select_dtypes(include = \"number\")\n",
    "xnew_num_pre = scaler.transform(xnew_num)\n",
    "\n",
    "xnew_pre = xnew_num_pre.join(xnew_cat_pre)\n",
    "\n",
    "ypred = model.predict(xnew_pre)\n",
    "\n",
    "xnew[\"Weight_pred\"] = ypred.round(2)\n",
    "\n",
    "xnew.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eab0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Wakad-Weekdays-5-7-pm-11th-Dec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
