{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c345d68",
   "metadata": {},
   "source": [
    "##### `Automated Preprocessing with sklearn pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2527d",
   "metadata": {},
   "source": [
    "##### `Problem Statement: Estimate Weight(Column) of Car based on other Factors(Columns)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce8ee62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore Warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd68be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>Max.Price</th>\n",
       "      <th>MPG.city</th>\n",
       "      <th>MPG.highway</th>\n",
       "      <th>AirBags</th>\n",
       "      <th>...</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Length</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Turn.circle</th>\n",
       "      <th>Rear.seat.room</th>\n",
       "      <th>Luggage.room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>177</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "      <td>26.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2705</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Manufacturer    Model   Type  Min.Price  Price  Max.Price  MPG.city  \\\n",
       "0   1        Acura  Integra  Small       12.9   15.9       18.8        25   \n",
       "\n",
       "   MPG.highway AirBags  ... Passengers Length  Wheelbase  Width  Turn.circle  \\\n",
       "0           31    None  ...          5    177        102     68           37   \n",
       "\n",
       "   Rear.seat.room Luggage.room  Weight   Origin           Make  \n",
       "0            26.5         11.0    2705  non-USA  Acura Integra  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step-1: Data Ingestion\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Cars93.csv\", keep_default_na=False, na_values =[\"\", \"NA\"])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91609397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AirBags            4\n",
       "Rear.seat.room     2\n",
       "Luggage.room      11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step-2: Data Sanity Checks \n",
    "#   Duplicate Removals \n",
    "#   Missing Values Replacement \n",
    "#   Less Unique Values Removal\n",
    "df.duplicated().sum()\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df.duplicated().sum()\n",
    "m = df.isna().sum()\n",
    "m[m>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21403e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If Exist Replace as below\n",
    "    # Categorical Values with most occured value\n",
    "    # Numeric value with mean or median\n",
    "# Create a replacer method to do the above replacing values\n",
    "\n",
    "def replacer(df):\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    num_cols = df.select_dtypes(include='number').columns\n",
    "    for col in df.columns:\n",
    "        if col in cat_cols:\n",
    "            mode = df[col].mode()[0]\n",
    "            df[col] = df[col].fillna(mode)\n",
    "        if col in num_cols:\n",
    "            mean = df[col].mean()\n",
    "            df[col] = df[col].fillna(mean)\n",
    "\n",
    "replacer(df)\n",
    "\n",
    "m = df.isna().sum()\n",
    "m[m>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9306a2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Note: Categoric values which has huge unique values needs to be discarded/dropped from dataframe as \n",
    "# One Hot Encoding will create large amoun of columns which is not ideal for prediction\n",
    "cat_uniq_cols = df.select_dtypes(include='object').nunique()\n",
    "high_cat_uniq_cols = cat_uniq_cols[cat_uniq_cols/len(df) > 0.9].index\n",
    "print(high_cat_uniq_cols)\n",
    "df = df.drop(columns = high_cat_uniq_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-3: Separate X and Y\n",
    "X = df.drop(columns=['id', 'Weight'])\n",
    "Y = df['Weight']\n",
    "# X.head(1), Y.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de2757f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74, 24), (19, 24))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step-4: Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2, random_state=21)\n",
    "xtrain.shape, xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a325de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-5: Apply Preprocessing on X\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "cat_cols = df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create number and categoric pipelines\n",
    "\n",
    "num_pipe = make_pipeline(\n",
    "   SimpleImputer(strategy='median'),\n",
    "   StandardScaler()\n",
    ")\n",
    "\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)\n",
    ")\n",
    "\n",
    "# Create preprocessing column transformer\n",
    "pre = ColumnTransformer(\n",
    "    (\"numeric\", num_pipe, num_cols),\n",
    "    (\"categoric\", cat_pipe, cat_cols)\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "pre.fit(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3a84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Wakad-Weekdays-5-7-pm-11th-Dec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
