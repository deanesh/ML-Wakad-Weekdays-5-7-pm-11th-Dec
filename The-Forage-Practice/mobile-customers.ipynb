{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0641b221",
   "metadata": {},
   "source": [
    "Absolutely! I can give you a **clear step-by-step guide** to anonymize this dataset while keeping it **useful for analysis**. Since your goal is for **InsightSpark data scientists**, we want to remove personally identifying info but preserve **features for modeling or analytics**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Remove Direct Identifiers**\n",
    "\n",
    "Columns that directly identify individuals should be **dropped**:\n",
    "\n",
    "* `customer_id` → unique identifier, can be removed unless you need a pseudonym ID\n",
    "* `username` → can identify a person → remove\n",
    "* `name` → remove\n",
    "* `email` → remove\n",
    "* `credit_card_number` → remove\n",
    "* `credit_card_security_code` → remove\n",
    "\n",
    "> These are **direct PII** that should not be in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Mask Location Data**\n",
    "\n",
    "Columns like `address`, `current_location`, and `residence` contain PII. Options:\n",
    "\n",
    "* `address` → remove\n",
    "* `current_location` → could be **generalized to city, state, or latitude/longitude bins**\n",
    "* `residence` → remove or generalize to city/state\n",
    "\n",
    "**Example of generalization:**\n",
    "\n",
    "* Replace `\"24675 Susan Valley, North Dianabury, MO 02475\"` with `\"MO\"` (state only)\n",
    "* Or convert coordinates into **grid or region codes**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Categorize Numeric Personal Data**\n",
    "\n",
    "Columns like `age` and `salary` can reveal identity. Instead of exact values:\n",
    "\n",
    "* **Age → age brackets** (bins)\n",
    "\n",
    "  * Example: `18–24`, `25–34`, `35–44`, `45–54`, `55+`\n",
    "* **Salary → income brackets**\n",
    "\n",
    "  * Example: `<30k`, `30k–50k`, `50k–70k`, `70k–100k`, `>100k`\n",
    "\n",
    "This preserves analytical usefulness while hiding exact numbers.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 4: Keep Useful Categorical Features**\n",
    "\n",
    "Columns like `gender`, `employer`, `job` can remain:\n",
    "\n",
    "* `gender` → keep (or encode as `M/F` or `Other`)\n",
    "* `employer` → could keep, or generalize to **industry**\n",
    "* `job` → could keep, or generalize to **job category**\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 5: Mask Financial Data**\n",
    "\n",
    "`credit_card_provider` may be okay to keep if you want insights on payment patterns. Otherwise, remove.\n",
    "\n",
    "* **Recommendation:** remove all credit card columns (`number`, `security code`, `expire`)\n",
    "* Keep `provider` if analysis requires it.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 6: Create Pseudonym ID (Optional)**\n",
    "\n",
    "* If you need a unique ID for analysis (e.g., to track transactions across tables), create a **random numeric or hash ID**:\n",
    "\n",
    "```python\n",
    "df['customer_pseudo_id'] = range(1, len(df)+1)\n",
    "```\n",
    "\n",
    "* This allows linking records without exposing `customer_id`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 7: Save Anonymized Dataset**\n",
    "\n",
    "* Save to a new CSV, e.g., `mobile_customers_anonymized.csv`:\n",
    "\n",
    "```python\n",
    "df_anonymized.to_csv(\"mobile_customers_anonymized.csv\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **Columns after anonymization**\n",
    "\n",
    "| Original Column           | Action     | Suggested Transformation |\n",
    "| ------------------------- | ---------- | ------------------------ |\n",
    "| customer_id               | Remove     | Optional pseudonym ID    |\n",
    "| date_registered           | Keep       | Can remain as-is         |\n",
    "| username                  | Remove     | -                        |\n",
    "| name                      | Remove     | -                        |\n",
    "| gender                    | Keep       | Categorical              |\n",
    "| address                   | Remove     | or keep only city/state  |\n",
    "| email                     | Remove     | -                        |\n",
    "| birthdate                 | Convert    | Calculate `age` and bin  |\n",
    "| current_location          | Generalize | city/state or region     |\n",
    "| residence                 | Remove     | or generalize            |\n",
    "| employer                  | Optional   | keep or map to industry  |\n",
    "| job                       | Optional   | keep or map to category  |\n",
    "| age                       | Bin        | e.g., 18–24, 25–34…      |\n",
    "| salary                    | Bin        | e.g., <30k, 30–50k…      |\n",
    "| credit_card_provider      | Optional   | keep if useful           |\n",
    "| credit_card_number        | Remove     | -                        |\n",
    "| credit_card_security_code | Remove     | -                        |\n",
    "| credit_card_expire        | Remove     | -                        |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40dcae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymization complete! Saved to 'mobile_customers_anonymized.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load Excel input\n",
    "# -------------------------\n",
    "df = pd.read_excel(\"mobile_customers.xlsx\")  # Input Excel file\n",
    "\n",
    "# -------------------------\n",
    "# 2. Remove direct identifiers\n",
    "# -------------------------\n",
    "columns_to_drop = [\n",
    "    'customer_id', 'username', 'name', 'email',\n",
    "    'credit_card_number', 'credit_card_security_code', 'credit_card_expire', 'address', 'residence'\n",
    "]\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# -------------------------\n",
    "# 3. Handle birthdate → age bins\n",
    "# -------------------------\n",
    "if 'birthdate' in df.columns and 'age' not in df.columns:\n",
    "    df['birthdate'] = pd.to_datetime(df['birthdate'], errors='coerce')\n",
    "    df['age'] = (pd.Timestamp('today') - df['birthdate']).dt.days // 365\n",
    "\n",
    "# Age bins\n",
    "bins = [0, 24, 34, 44, 54, 64, 100]\n",
    "labels = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Handle salary → salary bins\n",
    "# -------------------------\n",
    "salary_bins = [0, 30000, 50000, 70000, 100000, 1e9]\n",
    "salary_labels = ['<30k', '30-50k', '50-70k', '70-100k', '>100k']\n",
    "df['salary_bracket'] = pd.cut(df['salary'], bins=salary_bins, labels=salary_labels, right=False)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Generalize location\n",
    "# -------------------------\n",
    "if 'current_location' in df.columns:\n",
    "    df['current_location_general'] = df['current_location'].apply(\n",
    "        lambda x: str([round(float(coord), 1) for coord in eval(x)]) if pd.notnull(x) else None\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# 6. Optional: pseudonym ID\n",
    "# -------------------------\n",
    "df['customer_pseudo_id'] = range(1, len(df)+1)\n",
    "\n",
    "# -------------------------\n",
    "# 7. Save anonymized data to Excel\n",
    "# -------------------------\n",
    "df.to_excel(\"mobile_customers_anonymized.xlsx\", index=False)\n",
    "\n",
    "print(\"Anonymization complete! Saved to 'mobile_customers_anonymized.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38535f2e",
   "metadata": {},
   "source": [
    "**Proposal: Leveraging @CommBank Twitter Data for Business Insights**\n",
    "\n",
    "**Background:**\n",
    "Twitter is a rich source of real-time, publicly available data about customer sentiment, engagement, and emerging trends. The @CommBank Twitter account provides insights into CommBank’s communication, customer interactions, and reactions to products and services. Using this data, InsightSpark can extract actionable insights to guide marketing, product development, and customer experience strategies.\n",
    "\n",
    "**Objective:**\n",
    "To use publicly available Twitter data from @CommBank to generate insights into customer sentiment, engagement patterns, and trending topics that can inform business strategy and competitive analysis.\n",
    "\n",
    "**Proposed Approach:**\n",
    "\n",
    "1. **Data Collection:**\n",
    "\n",
    "   * Use the **Twitter API** (v2) to access public tweets, replies, retweets, and likes related to @CommBank.\n",
    "   * Collect tweet metadata, including timestamps, tweet content, user location (if available), engagement metrics (likes, retweets, replies), and hashtags.\n",
    "   * Consider streaming data for real-time insights or historical data for trend analysis.\n",
    "\n",
    "2. **Data Analysis & Insights:**\n",
    "\n",
    "   * **Sentiment Analysis:** Use NLP techniques to classify tweets as positive, negative, or neutral. This can reveal how customers feel about CommBank’s services, campaigns, or announcements.\n",
    "   * **Engagement Patterns:** Analyze which types of tweets (promotional, informational, or customer service responses) generate the most engagement.\n",
    "   * **Trending Topics & Hashtags:** Identify the most discussed topics or hashtags to understand what drives conversations about the bank.\n",
    "   * **Customer Pain Points:** Monitor replies and complaints to detect recurring issues or service gaps.\n",
    "   * **Competitor Benchmarking:** Compare engagement and sentiment against other financial institutions on Twitter.\n",
    "\n",
    "3. **Visualization & Reporting:**\n",
    "\n",
    "   * Build dashboards to track sentiment trends, top-performing tweets, and emerging topics over time.\n",
    "   * Provide monthly or quarterly reports highlighting actionable insights for marketing, product teams, and customer service improvements.\n",
    "\n",
    "**Potential Business Benefits:**\n",
    "\n",
    "* Improve customer engagement by understanding preferences and sentiment.\n",
    "* Identify service gaps or emerging issues before they escalate.\n",
    "* Optimize marketing and communication strategies based on what resonates with customers.\n",
    "* Support competitive intelligence and benchmarking against other banks.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. Register for a Twitter Developer account and obtain API access.\n",
    "2. Define the scope of data collection (e.g., timeframe, tweet types).\n",
    "3. Develop Python scripts or use data analysis tools to collect and process the data.\n",
    "4. Build dashboards and reports for InsightSpark’s stakeholders.\n",
    "\n",
    "**Conclusion:**\n",
    "By systematically analyzing the @CommBank Twitter account, InsightSpark can gain a deeper understanding of customer sentiment, engagement drivers, and market trends. This will enable data-driven decision-making in marketing, customer experience, and competitive strategy.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also **write a concise 1-paragraph version** suitable for direct submission into a text field. It will be short, impactful, and still professional.\n",
    "\n",
    "Do you want me to do that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5bc61",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Wakad-Weekdays-5-7-pm-11th-Dec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
