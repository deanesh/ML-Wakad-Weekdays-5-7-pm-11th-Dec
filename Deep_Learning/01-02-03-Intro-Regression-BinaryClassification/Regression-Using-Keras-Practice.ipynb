{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec25aacd",
   "metadata": {},
   "source": [
    "##### Regression Using Keras\n",
    "Features Col:  AT-Atmospheric Temp, V-Vacuum Pressure, AP-Atmospheric Pressure, RH-Relative Humidity\n",
    "\n",
    "Target Col: PE - Power O/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd78df95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed count: 41\n",
      "Null Values does not exist\n",
      "Train MSE: 20.25 , Train MAE: 3.55\n",
      "Test MSE: 20.57 , Test MAE: 3.58\n",
      "Train Model Metrics: [RMSE : 4.50, MAE: 3.55, MAPE: 0.78%, r2_score: 92.96%]\n",
      "Test Model Metrics: [RMSE : 4.54, MAE: 3.58, MAPE: 0.79%, r2_score: 93.18%]\n"
     ]
    }
   ],
   "source": [
    "from warnings import filterwarnings; filterwarnings('ignore')\n",
    "\n",
    "# Step-1: Data Ingestion\n",
    "#-----------------------\n",
    "\n",
    "import pandas as pd; df = pd.read_csv('PowerPlant.csv'); df.head(2)\n",
    "\n",
    "# Step-2: Data Sanity Checks - Duplicate Removal , Null checks, High Categorical Non Unique Removal etc...\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "duplicate_count = df.duplicated().sum()\n",
    "if duplicate_count > 0:\n",
    "    df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    print('Duplicates removed count:', duplicate_count)\n",
    "else:\n",
    "    print('No Duplicates found..')\n",
    "\n",
    "m = df.isna().sum()\n",
    "mm = m[m > 0]\n",
    "if not mm.empty:\n",
    "    print('Null Values Found')\n",
    "else:\n",
    "    print('Null Values does not exist')\n",
    "\n",
    "# Step-3: Separate X and Y\n",
    "#-------------------------\n",
    "\n",
    "X = df.drop(columns=['PE']); Y = df[['PE']]\n",
    "\n",
    "# Step-4: Apply Train Test Split\n",
    "#------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step-5: Apply Preprocessing on X\n",
    "#---------------------------------\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_cols = X.select_dtypes(include='number').columns\n",
    "num_pipe = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n",
    "pre = ColumnTransformer([('num', num_pipe, num_cols)]).set_output(transform='pandas')\n",
    "pre.fit(xtrain)\n",
    "\n",
    "xtrain_pre = pre.transform(xtrain); xtest_pre = pre.transform(xtest)\n",
    "\n",
    "# Step-6: Build Network Model\n",
    "#----------------------------\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(xtrain_pre.shape[1], )),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(4, activation='relu'),\n",
    "        Dense(1, activation='relu')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(xtrain_pre, ytrain, validation_split=0.2, epochs=60, verbose=False)\n",
    "\n",
    "# Step-7: Evaluate Model\n",
    "#-----------------------\n",
    "\n",
    "train_mse, train_mae = model.evaluate(xtrain_pre, ytrain, verbose=False)\n",
    "print('Train MSE:', round(train_mse, 2), ', Train MAE:', round(train_mae, 2))\n",
    "\n",
    "test_mse, test_mae = model.evaluate(xtest_pre, ytest, verbose=False)\n",
    "print('Test MSE:', round(test_mse, 2), ', Test MAE:', round(test_mae, 2))\n",
    "\n",
    "# Evaluate Model\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    ypred = model.predict(x, verbose=False)\n",
    "    rmse = root_mean_squared_error(y, ypred)\n",
    "    mae = mean_absolute_error(y, ypred)\n",
    "    mape = mean_absolute_percentage_error(y, ypred),\n",
    "    r2 = r2_score(y, ypred)\n",
    "    return f'[RMSE : {rmse:.2f}, MAE: {mae:.2f}, MAPE: {mape[0]:.2%}, r2_score: {r2:.2%}]'\n",
    "\n",
    "print('Train Model Metrics:', evaluate_model(model, xtrain_pre, ytrain))\n",
    "print('Test Model Metrics:', evaluate_model(model, xtest_pre, ytest))\n",
    "\n",
    "# Step-8: Out of Sample Prediction\n",
    "xnew = pd.read_csv('test_PowerPlant.csv')\n",
    "xnew_pre = pre.transform(xnew)\n",
    "\n",
    "pe_preds = model.predict(xnew_pre, verbose=False)\n",
    "xnew['PE_Preds'] = pe_preds.round(2)\n",
    "xnew.to_csv('test_PowerPlant_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e45a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Wakad-Weekdays-5-7-pm-11th-Dec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
